{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSQFs_G8caeE"
      },
      "source": [
        "# 协作预备工作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c46c81-ddc4-4845-c637-aa53bae92931"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa84b56b-8bd1-45af-d523-e4467b5aed4e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5taGmPcWV-"
      },
      "source": [
        "# 获取代码和模型\n",
        "克隆官方仓库，将预训练模型（wav2lip_gan.pth）从Google Drive复制到项目目录。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798deda8-82ac-45e1-819f-2e57cb6113ec"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Wav2Lip' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8761505f-7996-4f6e-894a-7185ff05d864"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Wav2Lip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result_voice_1.mp4  test1.mp4  test1.wav  test.mp4  test.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8911f6-c782-407f-d462-fe3012ecffbb"
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: overwrite '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTaOS3ncFt6"
      },
      "source": [
        "# 获取先决条件\n",
        "卸载冲突的TensorFlow，安装项目依赖和指定版本的PyTorch。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f730c678-01fe-4a8d-e459-3102627a5971"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.11/dist-packages/tensorflow-2.18.0.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**接下来把requirements.txt里的东西改成这个：**\n",
        "\n",
        "librosa==0.9.1\n",
        "\n",
        "numpy\n",
        "\n",
        "opencv-contrib-python\n",
        "\n",
        "opencv-python\n",
        "\n",
        "tqdm\n",
        "\n",
        "numba"
      ],
      "metadata": {
        "id": "R3d5TKVoMWrh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be334de-283c-47ac-e987-bd9d51f7f991"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "!cd Wav2Lip && pip install pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa==0.9.1 (from -r requirements.txt (line 1))\n",
            "  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.61.0)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.1->-r requirements.txt (line 1))\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.9.1->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->-r requirements.txt (line 11)) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 1)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy, librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "Successfully installed librosa-0.9.1 resampy-0.4.3\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载S3FD模型权重，用于视频中的人脸检测。"
      ],
      "metadata": {
        "id": "yPkQQBjKUutG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0b9e6d-d688-499d-9e6e-1b64d95a9ecd"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-21 15:51:48--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  21.4MB/s    in 4.8s    \n",
            "\n",
            "2025-02-21 15:51:53 (17.8 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdIQfY2Kswcb"
      },
      "source": [
        "# 测试\n",
        "将视频（test1.mp4）和音频（test1.wav）从Google Drive复制到sample_data目录。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245d439f-7a13-4249-a638-206a6d2bf64c"
      },
      "source": [
        "!cp \"/content/gdrive/My Drive/Wav2Lip/test1.mp4\" \"/content/gdrive/My Drive/Wav2Lip/test1.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t     california_housing_train.csv  mnist_train_small.csv  test1.mp4\n",
            "california_housing_test.csv  mnist_test.csv\t\t   README.md\t\t  test1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "执行推理脚本，生成唇语同步视频。"
      ],
      "metadata": {
        "id": "Uj9QBAV9VPc-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cdf028-7af1-4745-b0ea-64adde38551a"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test1.mp4\" --audio \"../sample_data/test1.wav\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 269\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "(80, 838)\n",
            "Length of mel chunks: 238\n",
            "  0% 0/2 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "  0% 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 1/15 [00:19<04:32, 19.44s/it]\u001b[A\n",
            " 13% 2/15 [00:20<01:55,  8.85s/it]\u001b[A\n",
            " 20% 3/15 [00:22<01:06,  5.51s/it]\u001b[A\n",
            " 27% 4/15 [00:23<00:42,  3.91s/it]\u001b[A\n",
            " 33% 5/15 [00:25<00:29,  2.97s/it]\u001b[A\n",
            " 40% 6/15 [00:26<00:21,  2.41s/it]\u001b[A\n",
            " 47% 7/15 [00:27<00:16,  2.06s/it]\u001b[A\n",
            " 53% 8/15 [00:29<00:12,  1.83s/it]\u001b[A\n",
            " 60% 9/15 [00:30<00:10,  1.68s/it]\u001b[A\n",
            " 67% 10/15 [00:31<00:07,  1.57s/it]\u001b[A\n",
            " 73% 11/15 [00:33<00:05,  1.49s/it]\u001b[A\n",
            " 80% 12/15 [00:34<00:04,  1.45s/it]\u001b[A\n",
            " 87% 13/15 [00:36<00:02,  1.47s/it]\u001b[A\n",
            " 93% 14/15 [00:37<00:01,  1.47s/it]\u001b[A\n",
            "100% 15/15 [00:53<00:00,  3.58s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "Model loaded\n",
            "100% 2/2 [01:23<00:00, 41.90s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '../sample_data/test1.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf61.1.100\n",
            "  Duration: 00:00:10.47, bitrate: 768 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:10.35, start: 0.000000, bitrate: 2464 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 432x960 [SAR 1:1 DAR 9:20], 2465 kb/s, 23 fps, 23 tbr, 23 tbn, 23 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=23 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 432x960 [SAR 1:1 DAR 9:20], q=2-31, 23 fps, 11776 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=  238 fps= 35 q=-1.0 Lsize=    1447kB time=00:00:10.45 bitrate=1133.6kbits/s speed=1.52x    \n",
            "video:1349kB audio:91kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.465329%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mframe I:1     Avg QP:22.46  size: 22901\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mframe P:215   Avg QP:22.02  size:  5968\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mframe B:22    Avg QP:23.26  size:  3406\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mconsecutive B-frames: 84.9%  6.7%  5.0%  3.4%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mmb I  I16..4: 40.5% 51.2%  8.3%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mmb P  I16..4:  2.8%  9.0%  0.5%  P16..4: 37.4%  9.1%  3.8%  0.0%  0.0%    skip:37.2%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mmb B  I16..4:  1.5%  6.3%  0.3%  B16..8: 33.7%  6.7%  0.9%  direct: 2.6%  skip:48.0%  L0:67.9% L1:25.0% BI: 7.2%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0m8x8 transform intra:72.4% inter:82.6%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mcoded y,uvDC,uvAC intra: 44.2% 51.3% 2.7% inter: 17.0% 11.5% 0.2%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mi16 v,h,dc,p: 29% 39% 19% 13%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 21% 40%  3%  3%  4%  2%  3%  2%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 17% 16%  4%  7%  9%  7%  6%  4%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mi8c dc,h,v,p: 51% 24% 24%  2%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mref P L0: 75.9% 12.5%  8.5%  3.1%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mref B L0: 91.0%  7.7%  1.3%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mref B L1: 99.1%  0.9%\n",
            "\u001b[1;36m[libx264 @ 0x558f47ad69c0] \u001b[0mkb/s:1067.64\n",
            "\u001b[1;36m[aac @ 0x558f47ae0ac0] \u001b[0mQavg: 666.787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7zgfrQqbKom"
      },
      "source": [
        "## **尝试的变体**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9A9VDVbZAG"
      },
      "source": [
        "1.   使用更多填充以包括下巴区域"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2fbef3-3375-41e0-cc7f-13fa0c2f1ecf"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test1.mp4\" --audio \"../sample_data/sdfnsdkgnjksdgv.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 269\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  return f(*args, **kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\", line 155, in load\n",
            "    context = sf.SoundFile(path)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/soundfile.py\", line 690, in __init__\n",
            "    self._file = self._open(file, mode_int, closefd)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/soundfile.py\", line 1265, in _open\n",
            "    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\n",
            "soundfile.LibsndfileError: Error opening '../sample_data/sdfnsdkgnjksdgv.wav': System error.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 224, in main\n",
            "    wav = audio.load_wav(args.audio, 16000)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Wav2Lip/audio.py\", line 10, in load_wav\n",
            "    return librosa.core.load(path, sr=sr)[0]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/util/decorators.py\", line 88, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\", line 174, in load\n",
            "    y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\", line 198, in __audioread_load\n",
            "    with audioread.audio_open(path) as input_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/audioread/__init__.py\", line 127, in audio_open\n",
            "    return BackendClass(path)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/audioread/rawread.py\", line 59, in __init__\n",
            "    self._fh = open(filename, 'rb')\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../sample_data/sdfnsdkgnjksdgv.wav'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   使用 resize_factor 降低视频分辨率，因为低分辨率视频可能会获得更好的效果。因为该模型是在低分辨率人脸上训练的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95b7871-f06c-4dc9-a6eb-e3fccee1f4a5"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/test1.mp4\" --audio \"../sample_data/test1.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 269\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "(80, 838)\n",
            "Length of mel chunks: 238\n",
            "  0% 0/2 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "  0% 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 1/15 [00:05<01:22,  5.86s/it]\u001b[A\n",
            " 13% 2/15 [00:06<00:34,  2.67s/it]\u001b[A\n",
            " 20% 3/15 [00:06<00:19,  1.65s/it]\u001b[A\n",
            " 27% 4/15 [00:07<00:12,  1.18s/it]\u001b[A\n",
            " 33% 5/15 [00:07<00:09,  1.09it/s]\u001b[A\n",
            " 40% 6/15 [00:08<00:06,  1.34it/s]\u001b[A\n",
            " 47% 7/15 [00:08<00:05,  1.55it/s]\u001b[A\n",
            " 53% 8/15 [00:08<00:04,  1.74it/s]\u001b[A\n",
            " 60% 9/15 [00:09<00:03,  1.84it/s]\u001b[A\n",
            " 67% 10/15 [00:09<00:02,  1.87it/s]\u001b[A\n",
            " 73% 11/15 [00:10<00:02,  1.89it/s]\u001b[A\n",
            " 80% 12/15 [00:10<00:01,  1.86it/s]\u001b[A\n",
            " 87% 13/15 [00:11<00:01,  1.87it/s]\u001b[A\n",
            " 93% 14/15 [00:12<00:00,  1.87it/s]\u001b[A\n",
            "100% 15/15 [00:16<00:00,  1.12s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "Model loaded\n",
            "100% 2/2 [00:43<00:00, 21.67s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '../sample_data/test1.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf61.1.100\n",
            "  Duration: 00:00:10.47, bitrate: 768 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:10.35, start: 0.000000, bitrate: 1098 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 216x480 [SAR 1:1 DAR 9:20], 1094 kb/s, 23 fps, 23 tbr, 23 tbn, 23 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mprofile High, level 2.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=23 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 216x480 [SAR 1:1 DAR 9:20], q=2-31, 23 fps, 11776 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=  238 fps=155 q=-1.0 Lsize=     567kB time=00:00:10.45 bitrate= 444.6kbits/s speed=6.79x    \n",
            "video:469kB audio:91kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.304098%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mframe I:1     Avg QP:24.15  size: 10517\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mframe P:168   Avg QP:23.91  size:  2380\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mframe B:69    Avg QP:27.49  size:  1009\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mconsecutive B-frames: 57.6%  8.4%  8.8% 25.2%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mmb I  I16..4: 12.4% 64.3% 23.3%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mmb P  I16..4:  1.7%  5.0%  1.2%  P16..4: 33.3% 15.3%  8.3%  0.0%  0.0%    skip:35.2%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mmb B  I16..4:  0.4%  2.0%  0.5%  B16..8: 32.9%  9.6%  2.5%  direct: 2.4%  skip:49.8%  L0:50.5% L1:37.4% BI:12.1%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0m8x8 transform intra:64.1% inter:61.2%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mcoded y,uvDC,uvAC intra: 56.0% 53.6% 3.1% inter: 20.8% 9.5% 0.3%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mi16 v,h,dc,p: 24% 40% 17% 19%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 22% 34%  4%  3%  5%  2%  4%  4%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 18% 15%  6%  7%  9%  6%  7%  5%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mi8c dc,h,v,p: 51% 24% 23%  2%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mref P L0: 72.3% 15.8%  8.2%  3.7%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mref B L0: 89.9%  8.0%  2.1%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mref B L1: 98.4%  1.6%\n",
            "\u001b[1;36m[libx264 @ 0x5b9053f3f500] \u001b[0mkb/s:371.05\n",
            "\u001b[1;36m[aac @ 0x5b9053f23c00] \u001b[0mQavg: 666.787\n"
          ]
        }
      ]
    }
  ]
}